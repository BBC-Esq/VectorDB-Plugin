<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chat Models</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #161b22;
            color: #d0d0d0;
        }

        header {
            text-align: center;
            background-color: #3498db;
            color: #fff;
            padding: 20px;
            position: sticky;
            top: 0;
            z-index: 999;
        }

        main {
            max-width: 2160px;
            margin: 0 auto;
            padding: 20px;
        }

        img {
            display: block;
            margin: 0 auto;
            max-width: 100%;
            height: auto;
        }

        h1 {
            color: #333;
        }

        h2 {
            color: #f0f0f0;
            text-align: center;
        }

        p {
            text-indent: 35px;
        }

        table {
            border-collapse: collapse;
            width: 80%;
            margin: 50px auto;
        }

        th, td {
            text-align: left;
            padding: 8px;
            border-bottom: 1px solid #ddd;
        }

        th {
            background-color: #f2f2f2;
            color: #000;
        }

        footer {
            text-align: center;
            background-color: #333;
            color: #fff;
            padding: 10px;
        }
        
        code {
            background-color: #f9f9f9;
            border-radius: 3px;
            padding: 2px 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            color: #333;
        }
		
		a {
		  color: #0d4885; /* Change this to your desired color */
		}
		a:visited {
		  color: #0d4885; /* Color for visited links */
		}

    </style>
</head>
<body>
    <header>
        <h1>Chat Models</h1>
    </header>

    <main>
        <h2 style="color: #f0f0f0;" align="center">LM Studio</h2>

        <p>This program works with LM Studio andthe github repository contains detailed instructions.  These instructions pertain
		to the "local models" functionality added in version 5.0.0.</p>

        <h2 style="color: #f0f0f0;" align="center">"Local Models"</h2>

        <p>All of the models below can be used by selecting them within the database search tab when searching.</p>

        <img src="chart_chat.png" alt="Vision Models">

        <h2 style="color: #f0f0f0;" align="center">Tips</h2>

        <p>Regardless of whether you're using LM Studio or "local models," remember that chat models have a context limit just
        like vector models, usually 4096 tokens.  The following is an example of how this limit might be exceeded:
		
		<ol>
			<li>A chunk size setting of 1000 characters is used.</li>
			<li>13 chunks/contexts are returned.</li>
			<li>Each token is approximatelky 3.5 characters on average; thus, approximately 3,700 tokens are used so far.</li>
			<li>The user's query is 96 tokens.</li>
			<li>This leaves the chat model only 300 tokens within which to respond.</li>
		</ol>
        
        <p>If using LM Studio, make sure to increase the context length to what's needed.  When using the "local model" option,
		it's automatically set to the maximum context length that a model was trained on (some are more than 4096).</p>

        <p>The easiest way to ensure enough context is left for the chat model's response is to decrease the chunks size and/or number
		of contexts returned.  For a simple question-answer use case, if you construct your thoughtfully and usE a good vector
		model, you shouldn't need more than 3-6 chunks.</p>  For a typical book, for example, a good chunk setting is 1200 with
		an overlap of 600, returning up to 6 contexts.  High-end models like <code>instructor-xl</code> will usually return
		the relevant context in the first or second result.</p>
        
        <p>The "chunks only" checkbox within the search tab will display the chunks and not connect to LM Studio or the local model.
		This way you can test whether your chunk size setting is appropriate to encompass the concepts and ideas within the text.</p>
        
        <p>Experiment with different chat models using the same query.  Simply select a different model and click "Submit Question"
		again.  The same contexts and query will be sent to the new chat model so you can easily compare responses.</p>
    </main>

    <footer>
        www.chintellalaw.com
    </footer>
</body>
</html>